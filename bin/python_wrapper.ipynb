{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shallow ice flow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import firedrake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometry\n",
    "mesh = firedrake.UnitDiskMesh(5)\n",
    "R = 250e3\n",
    "mesh.coordinates.dat.data[:] *= R\n",
    "\n",
    "import icepack.plot\n",
    "\n",
    "fig, axes = icepack.plot.subplots()\n",
    "firedrake.triplot(mesh, axes=axes)\n",
    "axes.set_title(\"Mesh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data: ice bed, surface, thickness, velocity, and accumulation rate\n",
    "Q = firedrake.FunctionSpace(mesh, family='CG', degree=2) \n",
    "V = firedrake.VectorFunctionSpace(mesh, family='CG', degree=2)\n",
    "\n",
    "from firedrake import sqrt, exp, Constant, Function\n",
    "\n",
    "x, y = firedrake.SpatialCoordinate(mesh)\n",
    "r = sqrt(x**2 + y**2)\n",
    "\n",
    "# Plateau elevation\n",
    "b_base = Constant(400)\n",
    "\n",
    "# Max Elevation\n",
    "b_max = Constant(1400)\n",
    "\n",
    "# Radius of the plateau interior\n",
    "ro = 125e3\n",
    "\n",
    "# Radius of the ridge\n",
    "Ro = Constant(200e3)\n",
    "\n",
    "def tanh(z):\n",
    "    return (exp(z) - exp(-z))/(exp(z) + exp(-z))\n",
    "\n",
    "def theta(z):\n",
    "    return (tanh(z) + 1)/2\n",
    "\n",
    "def sech(z):\n",
    "    return 2/(exp(z) + exp(-z))\n",
    "\n",
    "# make a plateau on which the ice sheet sits\n",
    "a = Constant(50e3)\n",
    "eta = (sqrt(x**2 + y**2) - ro)/a\n",
    "\n",
    "b_expr_plateau = b_base * (1 - theta(3*eta))\n",
    "b = Function(Q).interpolate(b_expr_plateau)\n",
    "\n",
    "fig,axes = icepack.plot.subplots()\n",
    "kw = {\"vmin\": -600, \"vmax\":1200}\n",
    "colors = firedrake.tripcolor(b, axes=axes, shading=\"gouraud\", cmap=\"viridis\", **kw)\n",
    "axes.set_title(\"Bed Plateau\")\n",
    "fig.colorbar(colors, label=\"meters above sea level\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a ridge that runs along the edge of the plateau\n",
    "zta = (r- Ro)/a\n",
    "\n",
    "b_expr_ridge = (b_max - b_base) * sech(3*eta)\n",
    "b_expr = b_expr_plateau + b_expr_ridge\n",
    "b = Function(Q).interpolate(b_expr)\n",
    "\n",
    "fig, axes = icepack.plot.subplots()\n",
    "contors = firedrake.tripcolor(b, axes=axes, shading=\"gouraud\", cmap=\"viridis\", **kw)\n",
    "fig.colorbar(contors, label=\"meters above sea level\")\n",
    "axes.set_title(\"Bed Plateau and Ridge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut valleys into the ridge to get bed topography\n",
    "rho1 = Constant(1/4)\n",
    "mu1 = 1- rho1*theta(3 * (x - ro / 4) / a) * sech(2 * y / a)\n",
    "\n",
    "rho2 = Constant(3/8)\n",
    "mu2 = 1 - rho2 * theta(3 * (y - ro / 4) / a) * sech(2 * x / a)\n",
    "\n",
    "rho3 = Constant(1/2)\n",
    "mu3 = 1 - rho3 * theta(3 * (-x + ro / 4) / a) * sech(2 * y / a)\n",
    "\n",
    "rho4 = Constant(5/8)\n",
    "mu4 = 1 - rho4 * theta(3 * (-y + ro / 4) / a) * sech(2 * x / a)\n",
    "\n",
    "mu = mu1 * mu2 * mu3 * mu4\n",
    "S = 480/(1-Ro/R)\n",
    "\n",
    "b_expr_valleys = (b_max - b_base) * sech(3 * eta) * mu - theta(5 * zta) * S*zta\n",
    "b_expr = b_expr_plateau + b_expr_valleys\n",
    "b = Function(Q).interpolate(b_expr)\n",
    "\n",
    "fig, axes = icepack.plot.subplots()\n",
    "contours = firedrake.tripcolor(b, axes=axes, **kw)\n",
    "fig.colorbar(contours, label=\"meters above sea level\")\n",
    "axes.set_title(\"Bed Plateau, \\n Ridge, and Valleys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will put an Initial ice sheet on this bed\n",
    "\n",
    "from firedrake import max_value\n",
    "\n",
    "# surface elevation\n",
    "max_radius = 195e3\n",
    "dome_height = 2.4e3\n",
    "dome = dome_height*max_value(1-(x**2 + y**2)/(max_radius**2), 0)\n",
    "s0 = Function(Q).interpolate(dome)\n",
    "\n",
    "# thickness\n",
    "h0 = Function(Q).interpolate(max_value(s0 - b, 0))\n",
    "print(h0)\n",
    "\n",
    "fig, axes = icepack.plot.subplots()\n",
    "colors = firedrake.tripcolor(s0, axes=axes)\n",
    "fig.colorbar(colors, label=\"meters above sea level\")\n",
    "axes.set_title(\"Initial Ice \\n Surface Elevation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = icepack.plot.subplots()\n",
    "colors_b = firedrake.tripcolor(b, axes=axes)\n",
    "levels = np.linspace(100, 2300, 13)\n",
    "contours_h = firedrake.tricontour(h0, levels, axes=axes, cmap=\"Blues\")\n",
    "fig.colorbar(colors_b, label=\"meters\")\n",
    "axes.set_title(\"Initial Ice Thickness Contours \\n overlain on Bed Surface\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import icepack\n",
    "model = icepack.models.ShallowIce()\n",
    "\n",
    "# solve the problem; intializa the flow solver\n",
    "solver = icepack.solvers.FlowSolver(model) # initialize the flow solver with any argument that never changes throughout the simulation \n",
    "\n",
    "# Fluidity factor A\n",
    "T = Constant(273.15 -5)\n",
    "A = icepack.rate_factor(T)\n",
    "\n",
    "# compute the velocity field- call the diagnostic solver\n",
    "u0 = firedrake.Function(V) # pass in an empty function since we have no initial velocity field\n",
    "h = h0.copy(deepcopy=True)\n",
    "u = solver.diagnostic_solve(\n",
    "    velocity=u0,\n",
    "    thickness=h,\n",
    "    surface=s0,\n",
    "    fluidity=A,\n",
    ")\n",
    "# Note: this solver takes in the intial velocity of the ice field, thickness, surface, and fluidity factor as arguments and returns the velocity field\n",
    "\n",
    "# plot the velocity field\n",
    "fig, axes = icepack.plot.subplots()\n",
    "colors = firedrake.tripcolor(u, axes=axes)\n",
    "fig.colorbar(colors, label=\"meters / year\")\n",
    "axes.set_title(\"Initial Ice Velocity\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To evolve the ice sheet, we will need to choose a mass balance field\n",
    "\n",
    "from firedrake import min_value\n",
    "def mass_balance(s,max_a=0.5,da_ds=0.5/1000,ela=300.9):\n",
    "    return min_value((s-ela)*da_ds, max_a)\n",
    "\n",
    "ela = 300\n",
    "max_a = 0 \n",
    "da_ds = 0\n",
    "\n",
    "a = mass_balance(s0,ela=ela, max_a=max_a, da_ds=da_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # General simulation without any checkpoints ==========\n",
    "# # TO project the state of the ice sheet in time we will call the prognostic solver routine to update the ice thickness and then call the diagnostic solver to update the velocity field given current thickness.\n",
    "\n",
    "# # the following code runs the model forward 500 years with a 10 year time step until the ice sheet reaches steady state.\n",
    "# dt = 10\n",
    "# num_years = 500\n",
    "# num_timesteps = int(num_years/dt)\n",
    "\n",
    "# dh_max = np.zeros(num_timesteps)*np.nan\n",
    "# a = Function(Q)\n",
    "\n",
    "# for step in tqdm.trange(num_timesteps):\n",
    "#     h_old = h.copy(deepcopy=True)\n",
    "#     h = solver.prognostic_solve(\n",
    "#         dt,\n",
    "#         thickness=h,\n",
    "#         accumulation=a,\n",
    "#         velocity=u,\n",
    "#     )\n",
    "\n",
    "#     h.interpolate(max_value(h, 0))\n",
    "#     s = Function(Q).interpolate(b + h)\n",
    "#     u = solver.diagnostic_solve(\n",
    "#         velocity=u,\n",
    "#         thickness=h,\n",
    "#         surface=s,\n",
    "#         fluidity=A,\n",
    "#     )\n",
    "\n",
    "#     a.interpolate(mass_balance(s,ela=ela, max_a=max_a, da_ds=da_ds))\n",
    "\n",
    "#     dh = Function(Q).interpolate(h - h_old)\n",
    "#     dh_max[step] = dh.dat.data_ro.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Data Assmilation to Icepack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shallowIce_icepack(dt, h, u, b, a, ela, max_a, da_ds,step,dh_max):\n",
    "\n",
    "    # h and u are arrays convert then to firedrake functions\n",
    "    if isinstance(h, np.ndarray):\n",
    "        # Assuming `h` is a 1D array, project it into the function space `Q`\n",
    "        h_function = Function(Q)\n",
    "        h_function.dat.data[:] = h[:]  # Assign NumPy array values to the Function data\n",
    "        h = h_function\n",
    "\n",
    "    if isinstance(u, np.ndarray):\n",
    "        u_function = Function(V)\n",
    "        u_function.dat.data[:,:] = u[:,:]\n",
    "        u = u_function\n",
    "\n",
    "    h_old = h.copy(deepcopy=True)\n",
    "    h = solver.prognostic_solve(\n",
    "        dt,\n",
    "        thickness=h,\n",
    "        accumulation=a,\n",
    "        velocity=u,\n",
    "    )\n",
    "\n",
    "    h.interpolate(max_value(h, 0))\n",
    "    s = Function(Q).interpolate(b + h)\n",
    "    u = solver.diagnostic_solve(\n",
    "        velocity=u,\n",
    "        thickness=h,\n",
    "        surface=s,\n",
    "        fluidity=A,\n",
    "    )\n",
    "\n",
    "    a.interpolate(mass_balance(s,ela=ela, max_a=max_a, da_ds=da_ds))\n",
    "\n",
    "    dh = Function(Q).interpolate(h - h_old)\n",
    "    dh_max[step] = dh.dat.data_ro.max()\n",
    "\n",
    "    # convert the firedrake functions to arrays\n",
    "    h = h.dat.data_ro\n",
    "    u = u.dat.data_ro\n",
    "    s = s.dat.data_ro\n",
    "    dh = dh.dat.data_ro\n",
    "\n",
    "    return h, s, u, a, dh, dh_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation operators\n",
    "def Obs(u):\n",
    "    w = u\n",
    "    return w\n",
    "\n",
    "def JObs(u):\n",
    "    n = len(u)\n",
    "    D = np.eye(n)\n",
    "    return D\n",
    "\n",
    "# def Obs(huxg_virtual_obs, m_obs):\n",
    "#     # Determine the size of the observation vector\n",
    "#     n = huxg_virtual_obs.shape[0]\n",
    "#     m = m_obs\n",
    "\n",
    "#     # Initialize the H matrix with zeros\n",
    "#     H = np.zeros((m * 2 + 1, n))\n",
    "\n",
    "#     # Calculate the distance between measurements\n",
    "#     di = int((n - 2) / (2 * m))  # Python uses int for integer division\n",
    "\n",
    "#     # Fill in the H matrix\n",
    "#     for i in range(m):\n",
    "#         H[i, i * di] = 1\n",
    "#         H[m + i, int((n - 2) / 2) + i * di] = 1\n",
    "\n",
    "\n",
    "#     # Final element of H matrix\n",
    "#     H[m * 2, n - 2] = 1  # Adjust for 0-based indexing\n",
    "\n",
    "#     # Perform matrix multiplication\n",
    "#     z = H @ huxg_virtual_obs  # '@' operator for matrix multiplication in Python\n",
    "#     return z\n",
    "\n",
    "# # Jacobian of the observation operator ----------------------\n",
    "# def JObs(n_model, m_obs):\n",
    "#     # Initialize the H matrix with zeros\n",
    "#     n = n_model\n",
    "#     m = m_obs\n",
    "#     H = np.zeros((m * 2 + 1, n))\n",
    "\n",
    "#     # Calculate the distance between measurements\n",
    "#     di = int((n - 2) / (2 * m))  # Convert distance to an integer\n",
    "\n",
    "#     # Fill in the H matrix\n",
    "#     for i in range(m):  # Python uses 0-based indexing\n",
    "#         H[i, i * di] = 1  # Adjust for 0-based indexing\n",
    "#         H[m + i, int((n - 2) / 2) + i * di] = 1  # Adjust for 0-based indexing\n",
    "\n",
    "#     # Final element of H matrix\n",
    "#     H[m * 2, n - 2] = 1  # Adjust for 0-based indexing\n",
    "\n",
    "#     return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble Kalman Filters\n",
    "def EnKF(ubi,w,ObsOp,JObsOp,R,B):\n",
    "    \n",
    "    # The analysis step for the (stochastic) ensemble Kalman filter \n",
    "    # with virtual observations\n",
    "    if ubi.ndim == 3:\n",
    "        n,N = ubi.shape[0], ubi.shape[1]\n",
    "    else:\n",
    "        n,N = ubi.shape\n",
    "    # n,N = ubi.shape # n is the state dimension and N is the size of ensemble\n",
    "    m = w.shape[0] # m is the size of measurement vector\n",
    "\n",
    "    # compute the mean of forecast ensemble\n",
    "    ub = np.mean(ubi,1)    \n",
    "    # compute Jacobian of observation operator at ub\n",
    "    Dh = JObsOp(w)\n",
    "    # compute Kalman gain\n",
    "    print(Dh.shape, B.shape, R.shape)\n",
    " \n",
    "    D = Dh@B@Dh.T + R\n",
    "    K = B @ Dh.T @ np.linalg.inv(D)\n",
    "        \n",
    "    \n",
    "    wi = np.zeros([m,N])\n",
    "    uai = np.zeros([n,N])\n",
    "    for i in range(N):\n",
    "        # create virtual observations\n",
    "        # wi[:,i] = w + np.random.multivariate_normal(np.zeros(m), R)\n",
    "        wi[:,i] = w + np.random.normal(0, np.sqrt(R))\n",
    "        # compute analysis ensemble\n",
    "        uai[:,i] = ubi[:,i] + K @ (wi[:,i]-ObsOp(ubi[:,i]))\n",
    "        \n",
    "    # compute the mean of analysis ensemble\n",
    "    ua = np.mean(uai,1)    \n",
    "    # compute analysis error covariance matrix\n",
    "    P = (1/(N-1)) * (uai - ua.reshape(-1,1)) @ (uai - ua.reshape(-1,1)).T\n",
    "    return uai, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble parameters\n",
    "dt = 10\n",
    "tm = 500\n",
    "nt = int(tm/dt)\n",
    "t = np.linspace(0,tm,nt+1)\n",
    "\n",
    "#  initial conditions\n",
    "np.random.seed(seed=1)\n",
    "sig_m = 0.15 \n",
    "# R = sig_m**2 * np.eye(3) # observation error covariance matrix\n",
    "\n",
    "dt_m = 15 # time interval between observations\n",
    "tm_m = 150 # maximum time of observations\n",
    "nt_m = int(tm_m/dt_m) # number of observations instants\n",
    "ind_m = (np.linspace(int(dt_m/dt),int(tm_m/dt),nt_m)).astype(int) # indexes of observation instants\n",
    "t_m = t[ind_m] # time instants of observations\n",
    "\n",
    "sig_b= 0.1\n",
    "# Q = 0.0*np.eye(3)\n",
    "nd = h.dat.data_ro.shape[0]\n",
    "\n",
    "B = sig_b**2*np.eye(nd)\n",
    "ub = np.zeros([nd,nt+1])\n",
    "# ub[:,0] = u0b\n",
    "ua = np.zeros([nd,nt+1])\n",
    "# ua[:,0] = u0b\n",
    "n = nd #state dimension\n",
    "m = nd #measurement dimension\n",
    "# ensemble size\n",
    "N = 10\n",
    "\n",
    "# no of observations\n",
    "mobs = 10 \n",
    "params = {\"m_obs\": mobs}\n",
    "R = sig_m**2 * np.eye(nd) # observation error covariance matrix\n",
    "\n",
    "# time integration\n",
    "dh_max = np.zeros(nt)*np.nan\n",
    "a = Function(Q)\n",
    "\n",
    "s = Function(Q).interpolate(b + h.interpolate(max_value(h, 0)))\n",
    "h_old = h.copy(deepcopy=True)\n",
    "dh = Function(Q).interpolate(h - h_old)\n",
    "\n",
    "\n",
    "h0 = h.copy(deepcopy=True)\n",
    "u0 = u.copy(deepcopy=True)\n",
    "dh0 = dh.copy(deepcopy=True)\n",
    "s0 = s.copy(deepcopy=True)\n",
    "\n",
    "# ndl = h_old.dat.data_ro.shape[0]\n",
    "uval = np.zeros([nd,2,nt+1])\n",
    "hval = np.zeros([nd,nt+1])\n",
    "sval = np.zeros([nd,nt+1])\n",
    "dhval = np.zeros([nd,nt+1])\n",
    "uval[:,:,0] = u.dat.data_ro\n",
    "hval[:,0] = h.dat.data_ro\n",
    "sval[:,0] = s.dat.data_ro\n",
    "dhval[:,0] = dh.dat.data_ro\n",
    "\n",
    "km = 0\n",
    "wu = np.zeros([nd,2,nt_m])\n",
    "wh = np.zeros([nd,nt_m])\n",
    "ws = np.zeros([nd,nt_m])\n",
    "wdh = np.zeros([nd,nt_m])\n",
    "for step in tqdm.trange(nt):\n",
    "    hval[:,step+1], sval[:,step+1], uval[:,:,step+1] , a,  dhval[:,step+1], dh_max = \\\n",
    "                             shallowIce_icepack(dt, h, u, b, a, ela, max_a, da_ds, step, dh_max)\n",
    "\n",
    "    if (km<nt_m) and (step+1 == ind_m[km]):\n",
    "        wu[:,:,km] = Obs(uval[:,:,step+1]) + np.random.normal(0,sig_m,[nd,2])\n",
    "        wh[:,km] = Obs(hval[:,step+1]) + np.random.normal(0,sig_m,nd)\n",
    "        ws[:,km] = Obs(sval[:,step+1]) + np.random.normal(0,sig_m,nd)\n",
    "        wdh[:,km] = Obs(dhval[:,step+1]) + np.random.normal(0,sig_m,nd)\n",
    "        km = km + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the ensemble \n",
    "uai = np.zeros([nd,2,N])\n",
    "hai = np.zeros([nd,N])\n",
    "sai = np.zeros([nd,N])\n",
    "dhai = np.zeros([nd,N])\n",
    "for i in range(N):\n",
    "    uai[:,:,i] = u0.dat.data_ro +  np.random.normal(0,sig_m,[nd,2])\n",
    "    hai[:,i] = h0.dat.data_ro + np.random.normal(0,sig_m,nd)\n",
    "    sai[:,i] = s0.dat.data_ro + np.random.normal(0,sig_m,nd)\n",
    "    dhai[:,i] = dh0.dat.data_ro + np.random.normal(0,sig_m,nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the EnKF\n",
    "ub = np.zeros([nd,2,nt+1]); ub[:,:,0] = u0.dat.data_ro\n",
    "hb = np.zeros([nd,nt+1]); hb[:,0] = h0.dat.data_ro\n",
    "sb = np.zeros([nd,nt+1]); sb[:,0] = s0.dat.data_ro\n",
    "dhb = np.zeros([nd,nt+1]); dhb[:,0] = dh0.dat.data_ro\n",
    "\n",
    "ua = np.zeros([nd,2,nt+1]); ua[:,:,0] = u0.dat.data_ro\n",
    "ha = np.zeros([nd,nt+1]); ha[:,0] = h0.dat.data_ro\n",
    "sa = np.zeros([nd,nt+1]); sa[:,0] = s0.dat.data_ro\n",
    "dha = np.zeros([nd,nt+1]); dha[:,0] = dh0.dat.data_ro\n",
    "\n",
    "ua = np.zeros([nd,2,nt+1])\n",
    "ha = np.zeros([nd,nt+1])\n",
    "sa = np.zeros([nd,nt+1])\n",
    "dha = np.zeros([nd,nt+1])\n",
    "\n",
    "km = 0\n",
    "for k in tqdm.trange(nt):\n",
    "    # background state\n",
    "    hb[:,k+1], sb[:,k+1], ub[:,:,k+1], a, dhb[:,k+1], dh_max = \\\n",
    "                    shallowIce_icepack(dt,hb[:,k],ub[:,:,k],b,a,ela,max_a,da_ds,k,dh_max)\n",
    "    \n",
    "    # forecast step\n",
    "    for i in range(N):\n",
    "        hai[:,i], sai[:,i], uai[:,:,i], a, dhai[:,i], dh_max = \\\n",
    "                    shallowIce_icepack(dt,hai[:,i],uai[:,:,i],b,a,ela,max_a,da_ds,k,dh_max) \n",
    "        uai[:,:,i] = uai[:,:,i] + np.random.normal(0,sig_m,[nd,2])\n",
    "        hai[:,i] = hai[:,i] + np.random.normal(0,sig_m,nd)\n",
    "        sai[:,i] = sai[:,i] + np.random.normal(0,sig_m,nd)\n",
    "        dhai[:,i] = dhai[:,i] + np.random.normal(0,sig_m,nd)\n",
    "        \n",
    "    # compute the mean of the forecast ensemble\n",
    "    ua[:,:,k+1] = np.mean(uai,2)\n",
    "    ha[:,k+1] = np.mean(hai,1)\n",
    "    sa[:,k+1] = np.mean(sai,1)\n",
    "    dha[:,k+1] = np.mean(dhai,1)\n",
    "\n",
    "    # compute the forecast error covariance matrix\n",
    "    # Bu = (1/(N-1)) * (uai - ua[:,:,k+1].reshape(-1,2,1)) @ (uai - ua[:,:,k+1].reshape(-1,2,1)).transpose(0,2,1)\n",
    "    Bh = (1/(N-1)) * (hai - ha[:,k+1].reshape(-1,1)) @ (hai - ha[:,k+1].reshape(-1,1)).T\n",
    "    Bs = (1/(N-1)) * (sai - sa[:,k+1].reshape(-1,1)) @ (sai - sa[:,k+1].reshape(-1,1)).T\n",
    "    Bdh = (1/(N-1)) * (dhai - dha[:,k+1].reshape(-1,1)) @ (dhai - dha[:,k+1].reshape(-1,1)).T\n",
    "\n",
    "    if (km<nt_m) and (k+1 == ind_m[km]):\n",
    "        # analysis step\n",
    "        # uai, Bu = EnKF(uai,wu[:,:,km],Obs,JObs,R,Bu)\n",
    "        hai, Bh = EnKF(hai,wh[:,km],Obs,JObs,R,Bh)\n",
    "        # sai, Bs = EnKF(sai,ws[:,km],Obs,JObs,R,Bs)\n",
    "        # dhai, Bdh = EnKF(dhai,wdh[:km],Jbs,DObs,R,Bdh)\n",
    "\n",
    "        # compute the mean of the analysis ensemble\n",
    "        ua[:,:,k+1] = np.mean(uai,2)\n",
    "        # ha[:,k+1] = np.mean(hai,1)\n",
    "        # sa[:,k+1] = np.mean(sai,1)\n",
    "        # dha[:,k+1] = np.mean(dhai,1)\n",
    "        km = km + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will plot the final ice thickness and velocity fields. \n",
    "\n",
    "fig, axes = icepack.plot.subplots()\n",
    "colors = firedrake.tripcolor(u, axes=axes)\n",
    "fig.colorbar(colors, label=\"meters / year\")\n",
    "axes.set_title(\"Final Ice Velocity\")\n",
    "\n",
    "fig, axes = icepack.plot.subplots()\n",
    "colors = firedrake.tripcolor(s, axes=axes)\n",
    "fig.colorbar(colors, label=\"meters above sea level\")\n",
    "axes.set_title(\"Final Ice \\n Surface Elevation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will also look at how much the ice thickness has changed compoared to the original last time step.\n",
    "\n",
    "fig, axes = icepack.plot.subplots()\n",
    "thickness_change = Function(Q).interpolate(h - h0)\n",
    "colors = firedrake.tripcolor(\n",
    "    thickness_change, vmin=-300, vmax=+300, axes=axes, cmap=\"RdBu\"\n",
    ")\n",
    "fig.colorbar(colors, label=\"meters\")\n",
    "axes.set_title(\"Final - Initial\\nIce Thickness\")\n",
    "\n",
    "\n",
    "# If we plot the incremental change in thickness, then we can get a better sense of how close the ice sheet is to steady state.\n",
    "\n",
    "fig, axes = icepack.plot.subplots()\n",
    "colors = firedrake.tripcolor(\n",
    "    dh, vmin=-10, vmax=+10, axes=axes, cmap=\"RdBu\"\n",
    ")\n",
    "fig.colorbar(colors, label=\"meters\")\n",
    "axes.set_title(\"Final - Previous\\nIce Thickness\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we plot the maximum change in thickness through time, we can see how the ice sheet is approaching steady state.\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(dt * np.arange(nt), dh_max)\n",
    "plt.xlabel(\"years\")\n",
    "plt.ylabel(\"maximum change in thickness (meters)\")\n",
    "axes.set_title(\"Max Change in Ice Thickness at each Time Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firedrake",
   "language": "python",
   "name": "firedrake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
